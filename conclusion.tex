\noindent

This paper tries to present a solution for stream processing of short tasks in Spark Streaming - a space that we have found Spark Streaming lacking in practice.
We present three techniques to achieve this goal: 1) reduction of task overheads, 2) decentralized and elastic scheduling, and 3) leveraging modern network mediums of communication for faster transfer of data between the driver, schedulers and workers.

Much of this work is still in progress. We plan to continue working on this problem and evaluating the solutions we have proposed.
